{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple jupyter notebook to get acquainted with the main functions available in this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "from utils import (load_lhco_rd, add_gaussian_features, train_model_multirun)\n",
    "from plot_utils import plot_sic_curve_comparison\n",
    "from os.path import exists, join\n",
    "from os import mkdir\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from LHCO R&D dataset\n",
    "data = load_lhco_rd(\"./treebased_ad_files/lhco_rd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up general settings for the trainings\n",
    "\n",
    "# How often to re-run the entire ensemble training procedure\n",
    "num_runs = 2\n",
    "\n",
    "# How many models constitute a single ensemble\n",
    "ensembles_per_model = 5\n",
    "\n",
    "# Maximum numbers of iterations. Since we'll be using early stopping later,\n",
    "# this number will probably not be reached (usually the minimum validation\n",
    "# loss occurs within the first 20 iterations)\n",
    "max_iters = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell takes around 1 minute to run on a modern-era CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Histogrammed gradient boosting classifiers (HGB)\n",
    "\n",
    "# train_model_multirun is a wrapper for the entire training procedure.\n",
    "# The outputs are the losses of all models and runs as well as the model\n",
    "# instances themselves.\n",
    "#\n",
    "# The models are saved in the specified directory.\n",
    "# We choose the naming convention \"0G\" to indicate we are using the original\n",
    "# dataset without adding Gaussian noise features.\n",
    "full_losses_hgb_0G, models_hgb_0G = train_model_multirun(\n",
    "    data,\n",
    "    num_runs=num_runs, ensembles_per_model=ensembles_per_model,\n",
    "    max_iters=max_iters, model_type=\"HGB\", compute_val_weights=True,\n",
    "    save_model_dir=\"./models/models_hgb_0G\",\n",
    "    cv_mode=\"random\", early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create a copy of the data with 10 Gaussian noise features added\n",
    "data_10G = add_gaussian_features(data, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cell takes around 2 minutes to run on a modern-era CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We re-run the training with the exact same overall settings,\n",
    "# but now on the dataset including the Gaussian noise.\n",
    "full_losses_hgb_10G, models_hgb_10G = train_model_multirun(\n",
    "    data_10G,\n",
    "    num_runs=num_runs, ensembles_per_model=ensembles_per_model,\n",
    "    max_iters=max_iters, model_type=\"HGB\", compute_val_weights=True,\n",
    "    save_model_dir=\"./models/models_hgb_10G\",\n",
    "    cv_mode=\"random\", early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If not exists, create plots directory\n",
    "if not exists(\"./plots\"):\n",
    "    mkdir(\"./plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set recommended RC params\n",
    "plt.rcParams['pgf.rcfonts'] = False\n",
    "plt.rcParams['font.serif'] = []\n",
    "plt.rcParams['axes.formatter.useoffset'] = False\n",
    "plt.rcParams['lines.linewidth'] = 2\n",
    "plt.rcParams['errorbar.capsize'] = 2\n",
    "plt.rcParams['grid.linewidth'] = 0.5\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "plt.rcParams['legend.title_fontsize'] = 12\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "plt.rcParams['legend.frameon'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we create a significance improvement characteristic curve (SIC-curve) for the\n",
    "# two sets of models:\n",
    "\n",
    "# Set colors\n",
    "color_list = [\"black\", \"red\"]\n",
    "\n",
    "# Set linestyles (use matplotlib linestyles)\n",
    "linestyles = [\"solid\", \"solid\"]\n",
    "\n",
    "# Set model types (this time it's HGB for both cases, but one could also\n",
    "# compare different BDT algorithms or a DNN to a BDT)\n",
    "model_types = [\"HGB\", \"HGB\"]\n",
    "\n",
    "# Labels for the legend\n",
    "labels = [\"Baseline\", \"Baseline + 10G\"]\n",
    "\n",
    "plot_sic_curve_comparison([models_hgb_0G, models_hgb_10G],\n",
    "                          [data, data_10G],\n",
    "                          model_types=model_types,\n",
    "                          out_filename=join(\"plots\", \"gauss_compare_HGB.pdf\"),\n",
    "                          color_list=color_list,\n",
    "                          linestyles=linestyles,\n",
    "                          labels=labels,\n",
    "                          xlabel=r\"$\\epsilon_{S}$\",\n",
    "                          ylabel=r\"$\\epsilon_S/\\sqrt{\\epsilon_B}$\",\n",
    "                          max_y=20,\n",
    "                          title=\"BDT\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tree_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
